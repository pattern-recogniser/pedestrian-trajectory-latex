
@article{lecun_gradient-based_1998,
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	issn = {00189219},
	url = {http://ieeexplore.ieee.org/document/726791/},
	doi = {10.1109/5.726791},
	number = {11},
	urldate = {2018-05-20},
	journal = {Proceedings of the IEEE},
	author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	month = nov,
	year = {1998},
	pages = {2278--2324}
}

@article{brunetti_computer_2018,
	title = {Computer vision and deep learning techniques for pedestrian detection and tracking: {A} survey},
	volume = {300},
	issn = {09252312},
	shorttitle = {Computer vision and deep learning techniques for pedestrian detection and tracking},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S092523121830290X},
	doi = {10.1016/j.neucom.2018.01.092},
	language = {en},
	urldate = {2018-05-20},
	journal = {Neurocomputing},
	author = {Brunetti, Antonio and Buongiorno, Domenico and Trotta, Gianpaolo Francesco and Bevilacqua, Vitoantonio},
	month = jul,
	year = {2018},
	pages = {17--33}
}

@article{dollar_pedestrian_2012,
	title = {Pedestrian {Detection}: {An} {Evaluation} of the {State} of the {Art}},
	volume = {34},
	issn = {0162-8828, 2160-9292},
	shorttitle = {Pedestrian {Detection}},
	url = {http://ieeexplore.ieee.org/document/5975165/},
	doi = {10.1109/TPAMI.2011.155},
	number = {4},
	urldate = {2018-05-20},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Dollar, P. and Wojek, C. and Schiele, B. and Perona, P.},
	month = apr,
	year = {2012},
	pages = {743--761}
}

@inproceedings{murphey_accurate_2017,
	title = {Accurate pedestrian path prediction using neural networks},
	isbn = {978-1-5386-2726-6},
	url = {http://ieeexplore.ieee.org/document/8285398/},
	doi = {10.1109/SSCI.2017.8285398},
	urldate = {2018-05-20},
	publisher = {IEEE},
	author = {Murphey, Yi Lu and Liu, Chang and Tayyab, Muhammad and Narayan, Divyendu},
	month = nov,
	year = {2017},
	pages = {1--7},
	file = {10.1007%2F978-3-642-40602-7_18.ris:/Users/anjalikarimpil/Downloads/10.1007%2F978-3-642-40602-7_18.ris:application/x-research-info-systems}
}

@book{weickert_pattern_2013,
	address = {Berlin},
	series = {Lecture notes in computer science},
	title = {Pattern recognition: 35th {German} conference, {GCPR} 2013, {SaarbrÃŒcken}, {Germany}, {September} 3-6, 2013 ; proceedings},
	isbn = {978-3-642-40602-7 978-3-642-40601-0},
	shorttitle = {Pattern recognition},
	language = {eng},
	number = {8142},
	publisher = {Springer},
	editor = {Weickert, Joachim and Hein, Matthias and Schiele, Bernt},
	year = {2013},
	note = {OCLC: 862971954},
	file = {Table of Contents PDF:/Users/anjalikarimpil/Zotero/storage/JW4T5665/Weickert et al. - 2013 - Pattern recognition 35th German conference, GCPR .pdf:application/pdf}
}

@article{goldhammer_intentions_2018,
	title = {Intentions of {Vulnerable} {Road} {Users} - {Detection} and {Forecasting} by {Means} of {Machine} {Learning}},
	url = {http://arxiv.org/abs/1803.03577},
	abstract = {Avoiding collisions with vulnerable road users (VRUs) using sensor-based early recognition of critical situations is one of the manifold opportunities provided by the current development in the field of intelligent vehicles. As especially pedestrians and cyclists are very agile and have a variety of movement options, modeling their behavior in traffic scenes is a challenging task. In this article we propose movement models based on machine learning methods, in particular artificial neural networks, in order to classify the current motion state and to predict the future trajectory of VRUs. Both model types are also combined to enable the application of specifically trained motion predictors based on a continuously updated pseudo probabilistic state classification. Furthermore, the architecture is used to evaluate motion-specific physical models for starting and stopping and video-based pedestrian motion classification. A comprehensive dataset consisting of 1068 pedestrian and 494 cyclist scenes acquired at an urban intersection is used for optimization, training, and evaluation of the different models. The results show substantial higher classification rates and the ability to earlier recognize motion state changes with the machine learning approaches compared to interacting multiple model (IMM) Kalman Filtering. The trajectory prediction quality is also improved for all kinds of test scenes, especially when starting and stopping motions are included. Here, 37{\textbackslash}\% and 41{\textbackslash}\% lower position errors were achieved on average, respectively.},
	urldate = {2018-05-20},
	journal = {arXiv:1803.03577 [cs]},
	author = {Goldhammer, Michael and KÃ¶hler, Sebastian and Zernetsch, Stefan and Doll, Konrad and Sick, Bernhard and Dietmayer, Klaus},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.03577},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1803.03577 PDF:/Users/anjalikarimpil/Zotero/storage/KCMD5PVK/Goldhammer et al. - 2018 - Intentions of Vulnerable Road Users - Detection an.pdf:application/pdf;arXiv.org Snapshot:/Users/anjalikarimpil/Zotero/storage/6VQNT495/1803.html:text/html}
}

@incollection{leibe_pedestrian_2016,
	address = {Cham},
	title = {Pedestrian {Behavior} {Understanding} and {Prediction} with {Deep} {Neural} {Networks}},
	volume = {9905},
	isbn = {978-3-319-46447-3 978-3-319-46448-0},
	url = {http://link.springer.com/10.1007/978-3-319-46448-0_16},
	urldate = {2018-06-06},
	booktitle = {Computer {Vision} â {ECCV} 2016},
	publisher = {Springer International Publishing},
	author = {Yi, Shuai and Li, Hongsheng and Wang, Xiaogang},
	editor = {Leibe, Bastian and Matas, Jiri and Sebe, Nicu and Welling, Max},
	year = {2016},
	doi = {10.1007/978-3-319-46448-0_16},
	pages = {263--279}
}

@inproceedings{alahi_social_2016,
	title = {Social {LSTM}: {Human} {Trajectory} {Prediction} in {Crowded} {Spaces}},
	isbn = {978-1-4673-8851-1},
	shorttitle = {Social {LSTM}},
	url = {http://ieeexplore.ieee.org/document/7780479/},
	doi = {10.1109/CVPR.2016.110},
	urldate = {2018-06-06},
	publisher = {IEEE},
	author = {Alahi, Alexandre and Goel, Kratarth and Ramanathan, Vignesh and Robicquet, Alexandre and Fei-Fei, Li and Savarese, Silvio},
	month = jun,
	year = {2016},
	pages = {961--971},
	file = {_chat.txt:/Users/anjalikarimpil/Downloads/_chat.txt:text/plain}
}

@inproceedings{goldhammer_pedestrians_2014,
	title = {Pedestrian's {Trajectory} {Forecast} in {Public} {Traffic} with {Artificial} {Neural} {Networks}},
	isbn = {978-1-4799-5209-0},
	url = {http://ieeexplore.ieee.org/document/6977417/},
	doi = {10.1109/ICPR.2014.704},
	urldate = {2018-06-25},
	publisher = {IEEE},
	author = {Goldhammer, Michael and Doll, Konrad and Brunsmann, Ulrich and Gensler, Andre and Sick, Bernhard},
	month = aug,
	year = {2014},
	pages = {4110--4115}
}

@article{hasan_mx-lstm:_2018,
	title = {{MX}-{LSTM}: mixing tracklets and vislets to jointly forecast trajectories and head poses},
	shorttitle = {{MX}-{LSTM}},
	url = {http://arxiv.org/abs/1805.00652},
	abstract = {Recent approaches on trajectory forecasting use tracklets to predict the future positions of pedestrians exploiting Long Short Term Memory (LSTM) architectures. This paper shows that adding vislets, that is, short sequences of head pose estimations, allows to increase significantly the trajectory forecasting performance. We then propose to use vislets in a novel framework called MX-LSTM, capturing the interplay between tracklets and vislets thanks to a joint unconstrained optimization of full covariance matrices during the LSTM backpropagation. At the same time, MX-LSTM predicts the future head poses, increasing the standard capabilities of the long-term trajectory forecasting approaches. With standard head pose estimators and an attentional-based social pooling, MX-LSTM scores the new trajectory forecasting state-of-the-art in all the considered datasets (Zara01, Zara02, UCY, and TownCentre) with a dramatic margin when the pedestrians slow down, a case where most of the forecasting approaches struggle to provide an accurate solution.},
	urldate = {2018-06-25},
	journal = {arXiv:1805.00652 [cs]},
	author = {Hasan, Irtiza and Setti, Francesco and Tsesmelis, Theodore and Del Bue, Alessio and Galasso, Fabio and Cristani, Marco},
	month = may,
	year = {2018},
	note = {arXiv: 1805.00652},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1805.00652 PDF:/Users/anjalikarimpil/Zotero/storage/5EISFYHG/Hasan et al. - 2018 - MX-LSTM mixing tracklets and vislets to jointly f.pdf:application/pdf;arXiv.org Snapshot:/Users/anjalikarimpil/Zotero/storage/WSDDL3ZT/1805.html:text/html}
}

@article{hopfield_neural_1982,
	title = {Neural networks and physical systems with emergent collective computational abilities.},
	volume = {79},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/cgi/doi/10.1073/pnas.79.8.2554},
	doi = {10.1073/pnas.79.8.2554},
	language = {en},
	number = {8},
	urldate = {2018-07-30},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Hopfield, J. J.},
	month = apr,
	year = {1982},
	pages = {2554--2558}
}

@inproceedings{alahi_socially-aware_2014,
	title = {Socially-{Aware} {Large}-{Scale} {Crowd} {Forecasting}},
	isbn = {978-1-4799-5118-5},
	url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6909680},
	doi = {10.1109/CVPR.2014.283},
	urldate = {2018-08-12},
	publisher = {IEEE},
	author = {Alahi, Alexandre and Ramanathan, Vignesh and Fei-Fei, Li},
	month = jun,
	year = {2014},
	pages = {2211--2218}
}

@misc{abdelraouf_interactive_nodate,
	title = {Interactive visualization of artificial neural networks},
	url = {http://experiments.mostafa.io/public/ffbpann/},
	abstract = {A web-based interactive step-by-step visualization of artificial neural networks. It aims to help visual learners gain visual intuition as to how artificial neural networks work.},
	urldate = {2018-08-19},
	author = {Abdelraouf, Mostafa},
	file = {Snapshot:/Users/anjalikarimpil/Zotero/storage/6DESVMQK/ffbpann.html:text/html}
}

@incollection{hutchison_pedestrian_2013,
	address = {Berlin, Heidelberg},
	title = {Pedestrian {Path} {Prediction} with {Recursive} {Bayesian} {Filters}: {A} {Comparative} {Study}},
	volume = {8142},
	isbn = {978-3-642-40601-0 978-3-642-40602-7},
	shorttitle = {Pedestrian {Path} {Prediction} with {Recursive} {Bayesian} {Filters}},
	url = {http://link.springer.com/10.1007/978-3-642-40602-7_18},
	urldate = {2018-08-19},
	booktitle = {Pattern {Recognition}},
	publisher = {Springer Berlin Heidelberg},
	author = {Schneider, Nicolas and Gavrila, Dariu M.},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Weickert, Joachim and Hein, Matthias and Schiele, Bernt},
	year = {2013},
	doi = {10.1007/978-3-642-40602-7_18},
	pages = {174--183}
}

@article{varshneya_human_2017,
	title = {Human {Trajectory} {Prediction} using {Spatially} aware {Deep} {Attention} {Models}},
	url = {http://arxiv.org/abs/1705.09436},
	abstract = {Trajectory Prediction of dynamic objects is a widely studied topic in the field of artificial intelligence. Thanks to a large number of applications like predicting abnormal events, navigation system for the blind, etc. there have been many approaches to attempt learning patterns of motion directly from data using a wide variety of techniques ranging from hand-crafted features to sophisticated deep learning models for unsupervised feature learning. All these approaches have been limited by problems like inefficient features in the case of hand crafted features, large error propagation across the predicted trajectory and no information of static artefacts around the dynamic moving objects. We propose an end to end deep learning model to learn the motion patterns of humans using different navigational modes directly from data using the much popular sequence to sequence model coupled with a soft attention mechanism. We also propose a novel approach to model the static artefacts in a scene and using these to predict the dynamic trajectories. The proposed method, tested on trajectories of pedestrians, consistently outperforms previously proposed state of the art approaches on a variety of large scale data sets. We also show how our architecture can be naturally extended to handle multiple modes of movement (say pedestrians, skaters, bikers and buses) simultaneously.},
	urldate = {2018-08-20},
	journal = {arXiv:1705.09436 [cs]},
	author = {Varshneya, Daksh and Srinivasaraghavan, G.},
	month = may,
	year = {2017},
	note = {arXiv: 1705.09436},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv\:1705.09436 PDF:/Users/anjalikarimpil/Zotero/storage/W8RTSBY2/Varshneya and Srinivasaraghavan - 2017 - Human Trajectory Prediction using Spatially aware .pdf:application/pdf;arXiv.org Snapshot:/Users/anjalikarimpil/Zotero/storage/Y9DV4W3C/1705.html:text/html}
}

@article{bartoli_context-aware_2017,
	title = {Context-{Aware} {Trajectory} {Prediction}},
	url = {http://arxiv.org/abs/1705.02503},
	abstract = {Human motion and behaviour in crowded spaces is influenced by several factors, such as the dynamics of other moving agents in the scene, as well as the static elements that might be perceived as points of attraction or obstacles. In this work, we present a new model for human trajectory prediction which is able to take advantage of both human-human and human-space interactions. The future trajectory of humans, are generated by observing their past positions and interactions with the surroundings. To this end, we propose a "context-aware" recurrent neural network LSTM model, which can learn and predict human motion in crowded spaces such as a sidewalk, a museum or a shopping mall. We evaluate our model on a public pedestrian datasets, and we contribute a new challenging dataset that collects videos of humans that navigate in a (real) crowded space such as a big museum. Results show that our approach can predict human trajectories better when compared to previous state-of-the-art forecasting models.},
	urldate = {2018-08-20},
	journal = {arXiv:1705.02503 [cs]},
	author = {Bartoli, Federico and Lisanti, Giuseppe and Ballan, Lamberto and Del Bimbo, Alberto},
	month = may,
	year = {2017},
	note = {arXiv: 1705.02503},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1705.02503 PDF:/Users/anjalikarimpil/Zotero/storage/47LE4X3Z/Bartoli et al. - 2017 - Context-Aware Trajectory Prediction.pdf:application/pdf;arXiv.org Snapshot:/Users/anjalikarimpil/Zotero/storage/Z8FMLZ9F/1705.html:text/html}
}

@article{vemula_social_2017,
	title = {Social {Attention}: {Modeling} {Attention} in {Human} {Crowds}},
	shorttitle = {Social {Attention}},
	url = {http://arxiv.org/abs/1710.04689},
	abstract = {Robots that navigate through human crowds need to be able to plan safe, efficient, and human predictable trajectories. This is a particularly challenging problem as it requires the robot to predict future human trajectories within a crowd where everyone implicitly cooperates with each other to avoid collisions. Previous approaches to human trajectory prediction have modeled the interactions between humans as a function of proximity. However, that is not necessarily true as some people in our immediate vicinity moving in the same direction might not be as important as other people that are further away, but that might collide with us in the future. In this work, we propose Social Attention, a novel trajectory prediction model that captures the relative importance of each person when navigating in the crowd, irrespective of their proximity. We demonstrate the performance of our method against a state-of-the-art approach on two publicly available crowd datasets and analyze the trained attention model to gain a better understanding of which surrounding agents humans attend to, when navigating in a crowd.},
	urldate = {2018-08-20},
	journal = {arXiv:1710.04689 [cs]},
	author = {Vemula, Anirudh and Muelling, Katharina and Oh, Jean},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.04689},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics},
	file = {arXiv\:1710.04689 PDF:/Users/anjalikarimpil/Zotero/storage/IL4TZS5P/Vemula et al. - 2017 - Social Attention Modeling Attention in Human Crow.pdf:application/pdf;arXiv.org Snapshot:/Users/anjalikarimpil/Zotero/storage/DZZPWR6F/1710.html:text/html}
}

@inproceedings{goldhammer_camera_2015,
	address = {London, United Kingdom},
	title = {Camera based pedestrian path prediction by means of polynomial least-squares approximation and multilayer perceptron neural networks},
	isbn = {978-1-4673-7606-8},
	url = {http://ieeexplore.ieee.org/document/7361171/},
	doi = {10.1109/IntelliSys.2015.7361171},
	urldate = {2018-08-20},
	booktitle = {2015 {SAI} {Intelligent} {Systems} {Conference} ({IntelliSys})},
	publisher = {IEEE},
	author = {Goldhammer, Michael and Kohler, Sebastian and Doll, Konrad and Sick, Bernhard},
	month = nov,
	year = {2015},
	pages = {390--399}
}

@article{keller_will_2014,
	title = {Will the {Pedestrian} {Cross}? {A} {Study} on {Pedestrian} {Path} {Prediction}},
	volume = {15},
	issn = {1524-9050, 1558-0016},
	shorttitle = {Will the {Pedestrian} {Cross}?},
	url = {http://ieeexplore.ieee.org/document/6632960/},
	doi = {10.1109/TITS.2013.2280766},
	number = {2},
	urldate = {2018-08-20},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Keller, Christoph G. and Gavrila, Dariu M.},
	month = apr,
	year = {2014},
	pages = {494--506}
}

@book{ivakhnenko_cybernetic_1973,
	series = {Jprs report},
	title = {Cybernetic {Predicting} {Devices}},
	url = {https://books.google.ie/books?id=FhwVNQAACAAJ},
	publisher = {CCM Information Corporation},
	author = {Ivakhnenko, A.G. and Lapa, V.G.},
	year = {1973}
}

@article{lecun_backpropagation_1989,
	title = {Backpropagation {Applied} to {Handwritten} {Zip} {Code} {Recognition}},
	volume = {1},
	issn = {0899-7667, 1530-888X},
	url = {http://www.mitpressjournals.org/doi/10.1162/neco.1989.1.4.541},
	doi = {10.1162/neco.1989.1.4.541},
	language = {en},
	number = {4},
	urldate = {2018-08-20},
	journal = {Neural Computation},
	author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
	month = dec,
	year = {1989},
	pages = {541--551}
}

@article{ciresan_multi-column_2012,
	title = {Multi-column deep neural network for traffic sign classification},
	volume = {32},
	issn = {08936080},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S0893608012000524},
	doi = {10.1016/j.neunet.2012.02.023},
	language = {en},
	urldate = {2018-08-20},
	journal = {Neural Networks},
	author = {CireÅan, Dan and Meier, Ueli and Masci, Jonathan and Schmidhuber, JÃŒrgen},
	month = aug,
	year = {2012},
	pages = {333--338}
}

@misc{noauthor_neural_nodate,
	title = {Neural {Networks} and {Deep} {Learning} - {Home}},
	url = {https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome},
	abstract = {If you want to break into cutting-edge AI, this course will help you do so. Deep learning engineers are highly sought after, and mastering deep learning will give you numerous new career opportunities. Deep learning is also a new "superpower" ...},
	language = {en},
	urldate = {2018-08-20},
	journal = {Coursera},
	file = {Snapshot:/Users/anjalikarimpil/Zotero/storage/YI2EZXEJ/welcome.html:text/html}
}

@book{goodfellow_deep_2016,
	title = {Deep {Learning}},
	publisher = {MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year = {2016}
}

@article{bhattacharyya_long-term_2017,
	title = {Long-{Term} {On}-{Board} {Prediction} of {People} in {Traffic} {Scenes} under {Uncertainty}},
	url = {http://arxiv.org/abs/1711.09026},
	abstract = {Progress towards advanced systems for assisted and autonomous driving is leveraging recent advances in recognition and segmentation methods. Yet, we are still facing challenges in bringing reliable driving to inner cities, as those are composed of highly dynamic scenes observed from a moving platform at considerable speeds. Anticipation becomes a key element in order to react timely and prevent accidents. In this paper we argue that it is necessary to predict at least 1 second and we thus propose a new model that jointly predicts ego motion and people trajectories over such large time horizons. We pay particular attention to modeling the uncertainty of our estimates arising from the non-deterministic nature of natural traffic scenes. Our experimental results show that it is indeed possible to predict people trajectories at the desired time horizons and that our uncertainty estimates are informative of the prediction error. We also show that both sequence modeling of trajectories as well as our novel method of long term odometry prediction are essential for best performance.},
	urldate = {2018-08-20},
	journal = {arXiv:1711.09026 [cs]},
	author = {Bhattacharyya, Apratim and Fritz, Mario and Schiele, Bernt},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.09026},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1711.09026 PDF:/Users/anjalikarimpil/Zotero/storage/HUN95EYG/Bhattacharyya et al. - 2017 - Long-Term On-Board Prediction of People in Traffic.pdf:application/pdf;arXiv.org Snapshot:/Users/anjalikarimpil/Zotero/storage/2J56ZWIT/1711.html:text/html}
}

@inproceedings{quintero_pedestrian_2014,
	address = {MI, USA},
	title = {Pedestrian path prediction using body language traits},
	isbn = {978-1-4799-3638-0},
	url = {http://ieeexplore.ieee.org/document/6856498/},
	doi = {10.1109/IVS.2014.6856498},
	urldate = {2018-08-20},
	booktitle = {2014 {IEEE} {Intelligent} {Vehicles} {Symposium} {Proceedings}},
	publisher = {IEEE},
	author = {Quintero, R. and Almeida, J. and Llorca, D. F. and Sotelo, M. A.},
	month = jun,
	year = {2014},
	pages = {317--323}
}

@incollection{schoeffmann_collision-free_2018,
	address = {Cham},
	title = {Collision-{Free} {LSTM} for {Human} {Trajectory} {Prediction}},
	volume = {10704},
	isbn = {978-3-319-73602-0 978-3-319-73603-7},
	url = {http://link.springer.com/10.1007/978-3-319-73603-7_9},
	urldate = {2018-08-20},
	booktitle = {{MultiMedia} {Modeling}},
	publisher = {Springer International Publishing},
	author = {Xu, Kaiping and Qin, Zheng and Wang, Guolong and Huang, Kai and Ye, Shuxiong and Zhang, Huidi},
	editor = {Schoeffmann, Klaus and Chalidabhongse, Thanarat H. and Ngo, Chong Wah and Aramvith, Supavadee and OâConnor, Noel E. and Ho, Yo-Sung and Gabbouj, Moncef and Elgammal, Ahmed},
	year = {2018},
	doi = {10.1007/978-3-319-73603-7_9},
	pages = {106--116}
}

@article{cho_properties_2014,
	title = {On the {Properties} of {Neural} {Machine} {Translation}: {Encoder}-{Decoder} {Approaches}},
	shorttitle = {On the {Properties} of {Neural} {Machine} {Translation}},
	url = {http://arxiv.org/abs/1409.1259},
	abstract = {Neural machine translation is a relatively new approach to statistical machine translation based purely on neural networks. The neural machine translation models often consist of an encoder and a decoder. The encoder extracts a fixed-length representation from a variable-length input sentence, and the decoder generates a correct translation from this representation. In this paper, we focus on analyzing the properties of the neural machine translation using two models; RNN Encoder--Decoder and a newly proposed gated recursive convolutional neural network. We show that the neural machine translation performs relatively well on short sentences without unknown words, but its performance degrades rapidly as the length of the sentence and the number of unknown words increase. Furthermore, we find that the proposed gated recursive convolutional network learns a grammatical structure of a sentence automatically.},
	urldate = {2018-08-23},
	journal = {arXiv:1409.1259 [cs, stat]},
	author = {Cho, Kyunghyun and van Merrienboer, Bart and Bahdanau, Dzmitry and Bengio, Yoshua},
	month = sep,
	year = {2014},
	note = {arXiv: 1409.1259},
	keywords = {Computer Science - Computation and Language, Statistics - Machine Learning},
	file = {arXiv\:1409.1259 PDF:/Users/anjalikarimpil/Zotero/storage/4I3Z75F9/Cho et al. - 2014 - On the Properties of Neural Machine Translation E.pdf:application/pdf;arXiv.org Snapshot:/Users/anjalikarimpil/Zotero/storage/M6ZHSAYS/1409.html:text/html}
}

@article{chung_empirical_2014,
	title = {Empirical {Evaluation} of {Gated} {Recurrent} {Neural} {Networks} on {Sequence} {Modeling}},
	url = {http://arxiv.org/abs/1412.3555},
	abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
	urldate = {2018-08-23},
	journal = {arXiv:1412.3555 [cs]},
	author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.3555},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv\:1412.3555 PDF:/Users/anjalikarimpil/Zotero/storage/YWT5ZHS3/Chung et al. - 2014 - Empirical Evaluation of Gated Recurrent Neural Net.pdf:application/pdf;arXiv.org Snapshot:/Users/anjalikarimpil/Zotero/storage/QZA4G46W/1412.html:text/html}
}

@article{yin_comparative_2017,
	title = {Comparative {Study} of {CNN} and {RNN} for {Natural} {Language} {Processing}},
	url = {http://arxiv.org/abs/1702.01923},
	abstract = {Deep neural networks (DNN) have revolutionized the field of natural language processing (NLP). Convolutional neural network (CNN) and recurrent neural network (RNN), the two main types of DNN architectures, are widely explored to handle various NLP tasks. CNN is supposed to be good at extracting position-invariant features and RNN at modeling units in sequence. The state of the art on many NLP tasks often switches due to the battle between CNNs and RNNs. This work is the first systematic comparison of CNN and RNN on a wide range of representative NLP tasks, aiming to give basic guidance for DNN selection.},
	urldate = {2018-08-23},
	journal = {arXiv:1702.01923 [cs]},
	author = {Yin, Wenpeng and Kann, Katharina and Yu, Mo and SchÃŒtze, Hinrich},
	month = feb,
	year = {2017},
	note = {arXiv: 1702.01923},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1702.01923 PDF:/Users/anjalikarimpil/Zotero/storage/WFPPC2ZA/Yin et al. - 2017 - Comparative Study of CNN and RNN for Natural Langu.pdf:application/pdf;arXiv.org Snapshot:/Users/anjalikarimpil/Zotero/storage/YC9NJT76/1702.html:text/html}
}

@inproceedings{deng_deep_2013,
	address = {Vancouver, BC, Canada},
	title = {A deep convolutional neural network using heterogeneous pooling for trading acoustic invariance with phonetic confusion},
	isbn = {978-1-4799-0356-6},
	url = {http://ieeexplore.ieee.org/document/6638952/},
	doi = {10.1109/ICASSP.2013.6638952},
	urldate = {2018-08-23},
	booktitle = {2013 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	publisher = {IEEE},
	author = {Deng, Li and Abdel-Hamid, Ossama and Yu, Dong},
	month = may,
	year = {2013},
	pages = {6669--6673}
}

@article{sak_fast_2015,
	title = {Fast and {Accurate} {Recurrent} {Neural} {Network} {Acoustic} {Models} for {Speech} {Recognition}},
	url = {http://arxiv.org/abs/1507.06947},
	abstract = {We have recently shown that deep Long Short-Term Memory (LSTM) recurrent neural networks (RNNs) outperform feed forward deep neural networks (DNNs) as acoustic models for speech recognition. More recently, we have shown that the performance of sequence trained context dependent (CD) hidden Markov model (HMM) acoustic models using such LSTM RNNs can be equaled by sequence trained phone models initialized with connectionist temporal classification (CTC). In this paper, we present techniques that further improve performance of LSTM RNN acoustic models for large vocabulary speech recognition. We show that frame stacking and reduced frame rate lead to more accurate models and faster decoding. CD phone modeling leads to further improvements. We also present initial results for LSTM RNN models outputting words directly.},
	urldate = {2018-08-23},
	journal = {arXiv:1507.06947 [cs, stat]},
	author = {Sak, HaÅim and Senior, Andrew and Rao, Kanishka and Beaufays, FranÃ§oise},
	month = jul,
	year = {2015},
	note = {arXiv: 1507.06947},
	keywords = {Computer Science - Machine Learning, Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	file = {arXiv\:1507.06947 PDF:/Users/anjalikarimpil/Zotero/storage/YBVIFCUF/Sak et al. - 2015 - Fast and Accurate Recurrent Neural Network Acousti.pdf:application/pdf;arXiv.org Snapshot:/Users/anjalikarimpil/Zotero/storage/9QLR3PUU/1507.html:text/html}
}

@article{li_constructing_2014,
	title = {Constructing {Long} {Short}-{Term} {Memory} based {Deep} {Recurrent} {Neural} {Networks} for {Large} {Vocabulary} {Speech} {Recognition}},
	url = {http://arxiv.org/abs/1410.4281},
	abstract = {Long short-term memory (LSTM) based acoustic modeling methods have recently been shown to give state-of-the-art performance on some speech recognition tasks. To achieve a further performance improvement, in this research, deep extensions on LSTM are investigated considering that deep hierarchical model has turned out to be more efficient than a shallow one. Motivated by previous research on constructing deep recurrent neural networks (RNNs), alternative deep LSTM architectures are proposed and empirically evaluated on a large vocabulary conversational telephone speech recognition task. Meanwhile, regarding to multi-GPU devices, the training process for LSTM networks is introduced and discussed. Experimental results demonstrate that the deep LSTM networks benefit from the depth and yield the state-of-the-art performance on this task.},
	urldate = {2018-08-23},
	journal = {arXiv:1410.4281 [cs]},
	author = {Li, Xiangang and Wu, Xihong},
	month = oct,
	year = {2014},
	note = {arXiv: 1410.4281},
	keywords = {Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv\:1410.4281 PDF:/Users/anjalikarimpil/Zotero/storage/YRBRARFW/Li and Wu - 2014 - Constructing Long Short-Term Memory based Deep Rec.pdf:application/pdf;arXiv.org Snapshot:/Users/anjalikarimpil/Zotero/storage/DCYGN69V/1410.html:text/html}
}

@inproceedings{deng_imagenet:_2009,
	address = {Miami, FL},
	title = {{ImageNet}: {A} large-scale hierarchical image database},
	isbn = {978-1-4244-3992-8},
	shorttitle = {{ImageNet}},
	url = {http://ieeexplore.ieee.org/document/5206848/},
	doi = {10.1109/CVPR.2009.5206848},
	urldate = {2018-08-23},
	booktitle = {2009 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and {Kai Li} and {Li Fei-Fei}},
	month = jun,
	year = {2009},
	pages = {248--255}
}

@article{lin_microsoft_2014,
	title = {Microsoft {COCO}: {Common} {Objects} in {Context}},
	shorttitle = {Microsoft {COCO}},
	url = {http://arxiv.org/abs/1405.0312},
	abstract = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
	urldate = {2018-08-23},
	journal = {arXiv:1405.0312 [cs]},
	author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and DollÃ¡r, Piotr},
	month = may,
	year = {2014},
	note = {arXiv: 1405.0312},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1405.0312 PDF:/Users/anjalikarimpil/Zotero/storage/P426QZ5Y/Lin et al. - 2014 - Microsoft COCO Common Objects in Context.pdf:application/pdf;arXiv.org Snapshot:/Users/anjalikarimpil/Zotero/storage/ILQHUMX3/1405.html:text/html}
}

@article{everingham_pascal_2010,
	title = {The {Pascal} {Visual} {Object} {Classes} ({VOC}) {Challenge}},
	volume = {88},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/10.1007/s11263-009-0275-4},
	doi = {10.1007/s11263-009-0275-4},
	language = {en},
	number = {2},
	urldate = {2018-08-23},
	journal = {International Journal of Computer Vision},
	author = {Everingham, Mark and Van Gool, Luc and Williams, Christopher K. I. and Winn, John and Zisserman, Andrew},
	month = jun,
	year = {2010},
	pages = {303--338}
}

@misc{noauthor_convolutional_nodate,
	title = {Convolutional {Neural} {Network} {Simple} {Tutorial} â czxttkl},
	url = {https://nb4799.neu.edu/wordpress/?p=246},
	language = {en-US},
	urldate = {2018-08-23},
	file = {Snapshot:/Users/anjalikarimpil/Zotero/storage/CYAJ59NW/wordpress.html:text/html}
}

@misc{noauthor_understanding_nodate,
	title = {Understanding {LSTM} {Networks} -- colah's blog},
	url = {http://colah.github.io/posts/2015-08-Understanding-LSTMs/},
	urldate = {2018-08-23},
	file = {Understanding LSTM Networks -- colah's blog:/Users/anjalikarimpil/Zotero/storage/7NIY378R/2015-08-Understanding-LSTMs.html:text/html}
}

@article{kingma_adam:_2014,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
	urldate = {2018-08-24},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv\:1412.6980 PDF:/Users/anjalikarimpil/Zotero/storage/AV8C992Q/Kingma and Ba - 2014 - Adam A Method for Stochastic Optimization.pdf:application/pdf;arXiv.org Snapshot:/Users/anjalikarimpil/Zotero/storage/65VUEK92/1412.html:text/html}
}

@misc{noauthor_neural_nodate-1,
	title = {Neural {Networks} for {Machine} {Learning}},
	url = {https://www.coursera.org/learn/neural-networks},
	abstract = {Neural Networks for Machine Learning from University of Toronto. Learn about artificial neural networks and how they're being used for machine learning, as applied to speech and object recognition, image segmentation, modeling language and human ...},
	language = {en},
	urldate = {2018-08-24},
	journal = {Coursera},
	file = {Snapshot:/Users/anjalikarimpil/Zotero/storage/FPUL7GHA/neural-networks.html:text/html}
}

@misc{cavaioni_deeplearning_2018,
	title = {{DeepLearning} series: {Sequence} {Models}},
	shorttitle = {{DeepLearning} series},
	url = {https://medium.com/machine-learning-bites/deeplearning-series-sequence-models-7855babeb586},
	abstract = {This blog will cover the different architectures for Recurrent Neural Networks, language models, and sequence generation. I will go overâŠ},
	urldate = {2018-08-24},
	journal = {Machine Learning bites},
	author = {Cavaioni, Michele},
	month = mar,
	year = {2018},
	file = {Snapshot:/Users/anjalikarimpil/Zotero/storage/Y6SGIA44/deeplearning-series-sequence-models-7855babeb586.html:text/html}
}

@article{hochreiter_long_1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667, 1530-888X},
	url = {http://www.mitpressjournals.org/doi/10.1162/neco.1997.9.8.1735},
	doi = {10.1162/neco.1997.9.8.1735},
	language = {en},
	number = {8},
	urldate = {2018-08-24},
	journal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, JÃŒrgen},
	month = nov,
	year = {1997},
	pages = {1735--1780}
}

@misc{noauthor_tensorflow:_2018,
	title = {tensorflow: {Computation} using data flow graphs for scalable machine learning},
	shorttitle = {tensorflow},
	url = {https://github.com/tensorflow/tensorflow},
	urldate = {2018-08-26},
	publisher = {tensorflow},
	month = aug,
	year = {2018},
	note = {original-date: 2015-11-07T01:19:20Z}
}

@misc{noauthor_keras_nodate,
	title = {Keras {Documentation}},
	url = {https://keras.io/},
	urldate = {2018-08-26},
	file = {Keras Documentation:/Users/anjalikarimpil/Zotero/storage/X3AXZVWE/keras.io.html:text/html}
}

@misc{noauthor_pytorch_nodate,
	title = {{PyTorch}},
	url = {https://pytorch.org/},
	abstract = {Tensors and Dynamic neural networks in Python
                    with strong GPU acceleration.},
	language = {en},
	urldate = {2018-08-26},
	file = {Snapshot:/Users/anjalikarimpil/Zotero/storage/YPDI4TPH/pytorch.org.html:text/html}
}

@misc{noauthor_microsoft_2018,
	title = {Microsoft {Cognitive} {Toolkit} ({CNTK}), an open source deep-learning toolkit},
	url = {https://github.com/Microsoft/CNTK},
	urldate = {2018-08-26},
	publisher = {Microsoft},
	month = aug,
	year = {2018},
	note = {original-date: 2015-11-26T09:52:06Z},
	keywords = {c-plus-plus, c-sharp, cntk, cognitive-toolkit, deep-learning, deep-neural-networks, distributed, java, machine-learning, neural-network, python}
}

@misc{noauthor_incubator-mxnet:_2018,
	title = {incubator-mxnet: {Lightweight}, {Portable}, {Flexible} {Distributed}/{Mobile} {Deep} {Learning} with {Dynamic}, {Mutation}-aware {Dataflow} {Dep} {Scheduler}; for {Python}, {R}, {Julia}, {Scala}, {Go}, {Javascript} and more},
	copyright = {Apache-2.0},
	shorttitle = {incubator-mxnet},
	url = {https://github.com/apache/incubator-mxnet},
	urldate = {2018-08-26},
	publisher = {The Apache Software Foundation},
	month = aug,
	year = {2018},
	note = {original-date: 2015-04-30T16:21:15Z},
	keywords = {artificial-intelligence, deep-learning, deep-neural-networks, distributed-systems, machine-learning, mxnet}
}

@misc{noauthor_sublime_nodate,
	title = {Sublime {Text} - {A} sophisticated text editor for code, markup and prose},
	url = {https://www.sublimetext.com/},
	urldate = {2018-08-26},
	file = {Sublime Text - A sophisticated text editor for code, markup and prose:/Users/anjalikarimpil/Zotero/storage/PMGKKTNQ/www.sublimetext.com.html:text/html}
}

@misc{noauthor_sklearn.preprocessing.minmaxscaler_nodate,
	title = {sklearn.preprocessing.{MinMaxScaler} â scikit-learn 0.19.2 documentation},
	url = {http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html},
	urldate = {2018-08-26},
	file = {sklearn.preprocessing.MinMaxScaler â scikit-learn 0.19.2 documentation:/Users/anjalikarimpil/Zotero/storage/EVREILZP/sklearn.preprocessing.MinMaxScaler.html:text/html}
}

@article{manh_scene-lstm:_2018,
	title = {Scene-{LSTM}: {A} {Model} for {Human} {Trajectory} {Prediction}},
	shorttitle = {Scene-{LSTM}},
	url = {http://arxiv.org/abs/1808.04018},
	abstract = {We develop a human movement trajectory prediction system that incorporates the scene information (Scene-LSTM) as well as human movement trajectories (Pedestrian movement LSTM) in the prediction process within static crowded scenes. We superimpose a two-level grid structure (scene is divided into grid cells each modeled by a scene-LSTM, which are further divided into smaller sub-grids for finer spatial granularity) and explore common human trajectories occurring in the grid cell (e.g., making a right or left turn onto sidewalks coming out of an alley; or standing still at bus/train stops). Two coupled LSTM networks, Pedestrian movement LSTMs (one per target) and the corresponding Scene-LSTMs (one per grid-cell) are trained simultaneously to predict the next movements. We show that such common path information greatly influences prediction of future movement. We further design a scene data filter that holds important non-linear movement information. The scene data filter allows us to select the relevant parts of the information from the grid cell's memory relative to a target's state. We evaluate and compare two versions of our method with the Linear and several existing LSTM-based methods on five crowded video sequences from the UCY [1] and ETH [2] datasets. The results show that our method reduces the location displacement errors compared to related methods and specifically about 80\% reduction compared to social interaction methods.},
	urldate = {2018-08-27},
	journal = {arXiv:1808.04018 [cs]},
	author = {Manh, Huynh and Alaghband, Gita},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.04018},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1808.04018 PDF:/Users/anjalikarimpil/Zotero/storage/MQK99D3N/Manh and Alaghband - 2018 - Scene-LSTM A Model for Human Trajectory Predictio.pdf:application/pdf;arXiv.org Snapshot:/Users/anjalikarimpil/Zotero/storage/EBKFPLFL/1808.html:text/html}
}